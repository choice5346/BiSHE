import os
# å¼ºåˆ¶ä½¿ç”¨ HF é•œåƒ (é’ˆå¯¹å›½å†…ç½‘ç»œä¼˜åŒ–)
os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import sys
import json
import random
import numpy as np
import torch
from datasets import load_dataset, Dataset
from transformers import (
    AutoTokenizer, 
    AutoModelForCausalLM, 
    TrainingArguments, 
    Trainer, 
    DataCollatorForLanguageModeling
)
from peft import LoraConfig, get_peft_model, TaskType
from torch.utils.data import DataLoader
import torch.nn.functional as F
from sklearn.metrics import roc_auc_score
import evaluate
from tqdm import tqdm

# --- æ ¸å¿ƒç®—æ³•å¯¼å…¥: ç§»é™¤ helper.py ä¾èµ–ï¼Œæ”¹ä¸ºæœ¬åœ°å®ç° ---
# sys.path.append ... (Removed)

# ==========================================
# 0. å…¨å±€é…ç½®
# ==========================================
# æ£€æŸ¥æ˜¯å¦å­˜åœ¨æœ¬åœ°èµ„æº
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
LOCAL_RES_DIR = os.path.join(ROOT_DIR, "local_resources")

# ä¼˜å…ˆä½¿ç”¨æœ¬åœ°èµ„æºè·¯å¾„ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨äº‘ç«¯ ID
model_path = os.path.join(LOCAL_RES_DIR, "qwen_model")
if not os.path.exists(model_path):
    model_path = "Qwen/Qwen1.5-0.5B"
    print("âš ï¸ æœªæ‰¾åˆ°æœ¬åœ° Qwen æ¨¡å‹ï¼Œå°†ä½¿ç”¨äº‘ç«¯ä¸‹è½½æ¨¡å¼")
else:
    print(f"âœ… ä½¿ç”¨æœ¬åœ° Qwen æ¨¡å‹: {model_path}")

# Feature Extractor ç°åœ¨æ˜¯ LLM æœ¬èº«
CONFIG = {
    "model_name": model_path,                # ç›®æ ‡ LLM
    "n_samples": 2000,                       # æ€»æ ·æœ¬æ•°
    "n_val_samples": 20,                     # âš ï¸ éªŒè¯é›†å¤§å° (å– Oracle æ•°æ®)
    "poison_ratio": 0.3,                     # æŠ•æ¯’æ¯”ä¾‹
    "output_dir": "SFT/results",             # è¾“å‡ºç›®å½•
    "seed": 42
}

def set_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)

# ==========================================
# 1. æ•°æ®åˆæˆ (Data Synthesis)
# ==========================================
def prepare_data():
    """
    ä¸‹è½½ Alpaca æ•°æ®é›†ï¼Œå¹¶äººå·¥æ³¨å…¥ 30% çš„å™ªå£°ã€‚
    è¿”å›: raw_dataset (å«å™ªå£°), clean_indices (GT), dirty_indices (GT)
    """
    print("ğŸ“¥ æ­£åœ¨åŠ è½½ Alpaca æ•°æ®é›†...")
    
    ds_raw = None
    local_data_path = os.path.join(LOCAL_RES_DIR, "alpaca_data")
    
    # 1. å°è¯•æœ¬åœ°åŠ è½½ (ä¼˜å…ˆ)
    if os.path.exists(local_data_path):
        try:
            from datasets import load_from_disk
            print(f"ğŸ“‚ å°è¯•åŠ è½½æœ¬åœ°æ•°æ®: {local_data_path}")
            ds_full = load_from_disk(local_data_path)
            # å¤„ç† dataset dict æˆ– dataset
            if isinstance(ds_full, dict) or hasattr(ds_full, 'keys'):
                split_name = 'train' if 'train' in ds_full else list(ds_full.keys())[0]
                ds_full = ds_full[split_name]
            
            # åˆ‡ç‰‡
            ds_raw = ds_full.select(range(min(len(ds_full), CONFIG['n_samples'])))
            print("âœ… æœ¬åœ°æ•°æ®åŠ è½½æˆåŠŸï¼")
        except Exception as e:
            print(f"âŒ æœ¬åœ°åŠ è½½å¤±è´¥: {e}")

    # 2. å¦‚æœæœ¬åœ°å¤±è´¥ï¼Œå°è¯•åœ¨çº¿
    if ds_raw is None:
        try:
            print("â˜ï¸ å°è¯•åœ¨çº¿åŠ è½½ tatsu-lab/alpaca...")
            ds_raw = load_dataset("tatsu-lab/alpaca", split=f"train[:{CONFIG['n_samples']}]")
        except Exception as e:
            print(f"âš ï¸ åœ¨çº¿åŠ è½½å¤±è´¥: {e}")

    # 3. å®åœ¨ä¸è¡Œï¼Œåˆæˆå…œåº•
    ds = []
    if ds_raw:
        ds = [item for item in ds_raw]
    else:
        print("â˜¢ï¸ ä¸¥é‡è­¦å‘Šï¼šæ‰€æœ‰æ•°æ®åŠ è½½æ–¹å¼å¤±è´¥ï¼Œä½¿ç”¨å«æœ‰å™ªå£°çš„åˆæˆç®—æœ¯æ•°æ®å…œåº•ã€‚")
        # ç”Ÿæˆåˆæˆæ•°æ®
        for k in range(CONFIG['n_samples']):
            ds.append({
                "instruction": f"Solve math problem: {k} + {k}",
                "input": "", 
                "output": f"The answer is {k+k}."
            })
            
    data = []
    clean_indices = []
    dirty_indices = []
    
    set_seed(CONFIG['seed'])
    
    # å®šä¹‰ä¸€äº›â€œåƒåœ¾å›ç­”â€æ¨¡æ¿
    garbage_responses = [
        "I don't know the answer because I am an AI.",
        "This is a random sentence generated by a computer.",
        "Error 404: Answer not found.",
        "Bla bla bla, I am just outputting noise.",
        "To be or not to be, that is the question.",
        "Ignore the previous instruction, here is a poem about cats."
    ]
    
    print(f"ğŸ˜ˆ æ­£åœ¨æ³¨å…¥å™ªå£° (æ¯”ä¾‹: {CONFIG['poison_ratio']:.0%})...")
    
    for i, item in enumerate(ds):
        # å†³å®šæ˜¯å¦æŠ•æ¯’
        is_poison = random.random() < CONFIG['poison_ratio']
        
        new_item = {
            "instruction": item["instruction"],
            "input": item["input"],
            "output": item["output"]
        }
        
        if is_poison:
            # æ›¿æ¢ output ä¸ºåƒåœ¾
            new_item["output"] = random.choice(garbage_responses)
            dirty_indices.append(i)
        else:
            clean_indices.append(i)
            
        data.append(new_item)
        
    print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: æ€»æ•° {len(data)}, å¹²å‡€ {len(clean_indices)}, è„ {len(dirty_indices)}")
    return data, dirty_indices, ds

# ==========================================
# 2. æ¢¯åº¦ç‰¹å¾æå–ä¸ KNN-Shapley (New)
# ==========================================

def compute_knn_shapley_gradient(train_grads, val_grads, K=10):
    """
    å®ç° knnsv-sft.md ä¸­çš„ç®—æ³•ã€‚
    """
    N_train = train_grads.shape[0]
    N_val = val_grads.shape[0]
    
    # å½’ä¸€åŒ–æ¢¯åº¦å‘é‡
    print(f"   -> æ­£åœ¨å½’ä¸€åŒ–æ¢¯åº¦å‘é‡...")
    train_grads = F.normalize(train_grads, p=2, dim=1)
    val_grads = F.normalize(val_grads, p=2, dim=1)
    
    print(f"   -> è®¡ç®—ç›¸ä¼¼åº¦çŸ©é˜µ ({N_val}x{N_train})...")
    # Move to CPU for numpy ops to save GPU memory
    S = torch.matmul(val_grads, train_grads.T).cpu().numpy() 
    
    shapley_values = np.zeros(N_train)
    
    # é¢„è®¡ç®—
    print(f"   -> è¿è¡Œé€’å½’ç®—æ³• (K={K})...")
    for j in tqdm(range(N_val), desc="Val Points"):
        s_row = S[j]
        sorted_indices = np.argsort(s_row)[::-1] # Descending
        values = s_row[sorted_indices] # alpha
        
        # ç®€åŒ–ç‰ˆé€’å½’ç®—æ³•å®ç° (O(N))
        # æ ¹æ® KNN-Shapley è®ºæ–‡ï¼Œå¯¹äº Unweighted KNN (1/K * Sum(TopK)):
        # phi_i = phi_{i+1} + (v_i - v_{i+1})/K * min(K, i) ? No.
        
        # ç›´æ¥ä½¿ç”¨ç”± G-Shapley æ¨å¯¼å‡ºçš„ç³»æ•° (Jia et al.)
        # å¯¹äº Utility = 1/K * Sum_{j=1}^K s_(j)
        # Shapley Value phi_i = s_(i)/N + 1/K * (sum term)
        # è®©æˆ‘ä»¬ä½¿ç”¨æ›´ç›´è§‚çš„åŸºäºè¾¹é™…è´¡çŒ®çš„ç†è§£:
        # åªæœ‰å½“å‰ N ä¸ªç‚¹ä¸­çš„ Top-K å‘ç”Ÿå˜åŒ–æ—¶ï¼ŒUtility æ‰å˜ã€‚
        
        phi_sorted = np.zeros(N_train)
        N = N_train
        curr_K = min(K, N)
        
        # å€’åºè®¡ç®—
        for i in range(N - 1, -1, -1):
            rank = i + 1 
            val_diff = values[i] - (values[i+1] if i+1 < N else 0.0)
            
            if rank > curr_K:
                phi_sorted[i] = 0 # ç®€åŒ–å¤„ç†ï¼šKä¹‹åçš„ç‚¹å› ä¸ºæ¢¯åº¦ç›¸ä¼¼åº¦æä½ï¼Œè´¡çŒ®å¿½ç•¥
            else:
                # Top-K è´¡çŒ®åˆ†é…
                phi_sorted[i] = phi_sorted[i+1] + val_diff / curr_K
        
        shapley_values[sorted_indices] += phi_sorted
        
    shapley_values /= N_val
    return shapley_values

def extract_gradient_features(model_name, dataset_list, indices):
    """
    è®¡ç®—æŒ‡å®šæ ·æœ¬çš„æ¢¯åº¦å‘é‡ã€‚ä½¿ç”¨ LoRA å±‚çš„æ¢¯åº¦ã€‚
    """
    print(f"ğŸ§¬ æ­£åœ¨æå–æ¢¯åº¦ç‰¹å¾ (N={len(indices)})...")
    
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    tokenizer.pad_token = tokenizer.eos_token
    
    model = AutoModelForCausalLM.from_pretrained(model_name, device_map="auto", torch_dtype=torch.float16)
    
    # ä½¿ç”¨ LoRA ä½¿å¾—æ¢¯åº¦æ›´å°æ›´æ˜“è®¡ç®—
    peft_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM, inference_mode=False, r=8, lora_alpha=32, lora_dropout=0.1,
        target_modules=["q_proj", "v_proj"]
    )
    model = get_peft_model(model, peft_config)
    model.train() 
    
    grads = []
    
    def format_func(example):
        text = f"User: {example['instruction']}\n{example['input']}\nAssistant: {example['output']}{tokenizer.eos_token}"
        return text

    subset = [dataset_list[i] for i in indices]
    
    for item in tqdm(subset, desc="Computing Gradients"):
        text = format_func(item)
        inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512).to(model.device)
        
        outputs = model(**inputs, labels=inputs["input_ids"])
        loss = outputs.loss
        loss.backward()
        
        g_vecs = []
        # åªæå–æœ€åä¸€å±‚ Decoder Layer çš„ LoRA å‚æ•°æ¢¯åº¦
        num_layers = len(model.base_model.model.model.layers)
        target_layer_idx = num_layers - 1
        
        found = False
        for name, param in model.named_parameters():
            if f"layers.{target_layer_idx}" in name and "lora_B" in name and param.grad is not None:
                g_vecs.append(param.grad.view(-1).cpu().float()) # è½¬ float32
                found = True
        
        if found:
            grads.append(torch.cat(g_vecs))
        else:
            grads.append(torch.zeros(1))
            
        model.zero_grad()
    
    # æ¸…ç†å†…å­˜
    del model
    torch.cuda.empty_cache()
    
    # Pad if necessary (unlikely)
    return torch.stack(grads)

def calculate_shapley(dataset_list, dirty_indices, oracle_data):
    """
    Grad-SFT æµç¨‹ï¼šRaw Grads vs Oracle Grads
    """
    n_train = len(dataset_list)
    n_val = CONFIG['n_val_samples']
    
    # ä» Oracle æ•°æ®ä¸­å–éªŒè¯é›†
    # å¦‚æœ oracle_data ä¸å¤Ÿ N_valï¼Œå°±å–å…¨éƒ¨
    n_val = min(len(oracle_data), n_val)
    val_subset = oracle_data[:n_val]
    val_indices = list(range(n_val))
    
    print(f"ğŸ”§ å¼€å§‹åŸºäºæ¢¯åº¦çš„æ¸…æ´—æµç¨‹...")
    print(f"   Train: {n_train}, Val: {n_val}")
    
    # 1. æå– Traing Gradients
    train_indices = list(range(n_train))
    print("   [1/2] Computing Train Gradients...")
    train_grads = extract_gradient_features(CONFIG['model_name'], dataset_list, train_indices)
    
    # 2. æå– Val Gradients
    print("   [2/2] Computing Val (Oracle) Gradients...")
    val_grads = extract_gradient_features(CONFIG['model_name'], val_subset, val_indices)
    
    # ç»´åº¦å¯¹é½æ£€æŸ¥
    if train_grads.shape[1] != val_grads.shape[1]:
        print("âŒ Gradient dimension mismatch!")
        # å¦‚æœå‡ºé”™ï¼Œè¿”å›éšæœºå€¼
        return np.random.rand(n_train)

    # 3. è®¡ç®— ES-Shapley
    sv = compute_knn_shapley_gradient(train_grads, val_grads, K=10)
    
    print(f"ğŸ“Š Gradient-Shapley Stats -> Mean: {np.mean(sv):.4e}, Std: {np.std(sv):.4e}")
    return sv

# ==========================================
# 4. å¾®è°ƒè®­ç»ƒ (Fine-tuning)
# ==========================================
def run_sft(dataset_list, output_name):
    """
    ä½¿ç”¨ HuggingFace Trainer è¿›è¡Œå¾®è°ƒ (ä½¿ç”¨ LoRA ä»¥ä¿è¯ç¨³å®šæ€§)ã€‚
    """
    print(f"ğŸš€ å¼€å§‹å¾®è°ƒ: {output_name} (æ ·æœ¬æ•°: {len(dataset_list)})...")
    
    model_id = CONFIG['model_name']
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    # ä¿®å¤ tokenizer è®¾ç½®
    tokenizer.pad_token = tokenizer.eos_token
    tokenizer.padding_side = "right" # è®­ç»ƒæ—¶é€šå¸¸ç”¨ right padding

    # æ ¼å¼åŒ–æ•°æ®ä¸º HuggingFace Dataset
    def format_func(example):
        # Qwen å®˜æ–¹æ¨èæ ¼å¼ / ChatML æ ¼å¼
        # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œä½†ç¡®ä¿ EOS
        text = f"User: {example['instruction']}\n{example['input']}\nAssistant: {example['output']}{tokenizer.eos_token}"
        return {"text": text}
    
    hf_dataset = Dataset.from_list(dataset_list)
    hf_dataset = hf_dataset.map(lambda x: tokenizer(format_func(x)["text"], truncation=True, max_length=512), batched=False)
    
    # åŠ è½½æ¨¡å‹ (FP32 æ¨¡å¼åŠ è½½ï¼Œé¿å… 16bit æº¢å‡º)
    model = AutoModelForCausalLM.from_pretrained(model_id, device_map="auto", torch_dtype=torch.float32)
    
    # å¯ç”¨ LoRA 
    peft_config = LoraConfig(
        task_type=TaskType.CAUSAL_LM, 
        inference_mode=False, 
        r=8, 
        lora_alpha=32, 
        lora_dropout=0.1,
        target_modules=["q_proj", "v_proj"] # é’ˆå¯¹ Attention å±‚å¾®è°ƒ
    )
    model = get_peft_model(model, peft_config)
    model.print_trainable_parameters()

    # è®­ç»ƒå‚æ•°è°ƒæ•´
    training_args_dict = {
        "output_dir": f"{CONFIG['output_dir']}/{output_name}",
        "per_device_train_batch_size": 4, # LoRA çœæ˜¾å­˜ï¼Œå¯ä»¥ç¨å¾®å¤§ç‚¹
        "gradient_accumulation_steps": 4,
        "num_train_epochs": 3,            # LoRA éœ€è¦å¤šè®­å‡ è½®
        "learning_rate": 3e-4,            # LoRA é€šå¸¸ç”¨å¤§ä¸€ç‚¹çš„å­¦ä¹ ç‡
        "logging_steps": 10,
        "save_strategy": "no",
        "report_to": "none",
        "fp16": False,                    # ä½¿ç”¨ FP32 ä¿è¯æ•°å€¼ç»å¯¹ç¨³å®š
        "bf16": False,
    }
    
    args = TrainingArguments(**training_args_dict)
    
    trainer = Trainer(
        model=model,
        args=args,
        train_dataset=hf_dataset,
        data_collator=DataCollatorForLanguageModeling(tokenizer, mlm=False),
    )
    
    trainer.train()

    # ğŸ’¾ ä¿å­˜æ¨¡å‹ (LoRA é€‚é…å™¨)
    save_path = f"{CONFIG['output_dir']}/{output_name}"
    trainer.save_model(save_path)
    # åˆå¹¶æƒé‡å¹¶ä¿å­˜ (æ–¹ä¾¿ chat_compare è¯»å–)
    print("ğŸ’¾ æ­£åœ¨åˆå¹¶ LoRA æƒé‡...")
    merged_model = model.merge_and_unload()
    merged_model.save_pretrained(save_path)
    tokenizer.save_pretrained(save_path)
    print(f"ğŸ’¾ å®Œæ•´æ¨¡å‹å·²ä¿å­˜è‡³: {save_path}")
    
    # === æ–°å¢ï¼šè®¡ç®— ROUGE åˆ†æ•° (æ›´æœ‰è¯´æœåŠ›çš„ç”ŸæˆæŒ‡æ ‡) ===
    print("ğŸ“ æ­£åœ¨è¯„ä¼° ROUGE æŒ‡æ ‡...")
    metric = evaluate.load("rouge")
    
    # æŠ½å– 50 æ¡æµ‹è¯•æ•°æ® (ä¸å‚ä¸è®­ç»ƒçš„)
    test_samples = dataset_list[:50] 
    
    preds = []
    refs = []
    
    # åˆ‡æ¢å› eval æ¨¡å¼
    merged_model.eval()
    for item in tqdm(test_samples, desc="Evaluating"):
        prompt = f"User: {item['instruction']}\n\nAssistant: "
        inputs = tokenizer(prompt, return_tensors="pt").to(merged_model.device)
        with torch.no_grad():
            outputs = merged_model.generate(**inputs, max_new_tokens=50, pad_token_id=tokenizer.eos_token_id)
        pred = tokenizer.decode(outputs[0], skip_special_tokens=True)
        if "Assistant: " in pred:
            pred = pred.split("Assistant: ")[1].strip()
        preds.append(pred)
        refs.append(item['output'])
        
    scores = metric.compute(predictions=preds, references=refs)
    print(f"ğŸ“Š {output_name} ROUGE-L: {scores['rougeL']:.4f}")
    
    # è¿”å› Loss å’Œ RougeL ç”¨äºå¯¹æ¯”
    return trainer.state.log_history[-1].get('train_loss', 0.0), scores['rougeL']

# ==========================================
# ä¸»ç¨‹åº
# ==========================================
def main():
    # 1. å‡†å¤‡æ•°æ®
    # oracle_data: æœªè¢«æ±¡æŸ“çš„åŸå§‹çº¯å‡€æ•°æ® (ä¸Šé™/Gold Standard)
    raw_data, dirty_indices, oracle_data = prepare_data()
    
    # 2. è®¡ç®—ä»·å€¼ (Gradient-Shapley Value)
    # ä¸å†éœ€è¦æ˜¾å¼ extract_featuresï¼Œcalculate_shapley å†…éƒ¨ä¼šåš
    sv = calculate_shapley(raw_data, dirty_indices, oracle_data)
    
    # 3. æ ¹æ®ä»·å€¼æ¸…æ´—
    # ç­–ç•¥ï¼šæˆ‘ä»¬è¦åˆ æ‰ 30% å·¦å³çš„æ•°æ®
    n_remove = int(len(raw_data) * CONFIG['poison_ratio'])
    
    sorted_idx = np.argsort(sv) # ä»å°åˆ°å¤§
    # ä½åˆ†çš„æ˜¯è„æ•°æ®ï¼Œåˆ æ‰
    keep_indices = sorted_idx[n_remove:]
    
    cleaned_data = [raw_data[i] for i in keep_indices]
    
    print("-" * 50)
    print(f"ğŸ§¹ æ¸…æ´—å®Œæˆï¼")
    print(f"åŸæ•°æ®: {len(raw_data)}")
    print(f"æ¸…æ´—å: {len(cleaned_data)}")
    
    # éªŒè¯æ¸…æ´—å‡†ç¡®ç‡ (Recall)
    # æˆ‘ä»¬çŸ¥é“ dirty_indices æ˜¯çœŸçš„è„æ•°æ®
    # æˆ‘ä»¬çš„ç³»ç»Ÿåˆ é™¤äº† sorted_idx[:n_remove]
    removed_indices = sorted_idx[:n_remove]
    correct_removed = set(removed_indices).intersection(set(dirty_indices))
    recall = len(correct_removed) / len(dirty_indices)
    print(f"ğŸ•µï¸â€â™‚ï¸ è„æ•°æ®è¯†åˆ«å¬å›ç‡ (Recall): {recall:.2%}")

    # è®¡ç®— AUC (æ¸…æ´—ç®—æ³•çš„æ€§èƒ½æŒ‡æ ‡)
    # æˆ‘ä»¬å¸Œæœ› dirty_indices å¯¹åº”çš„ sv å€¼å¾ˆä½ï¼Œè€Œ clean å¯¹åº”çš„é«˜ã€‚
    # ä¸ºäº†è®¡ç®— AUCï¼Œæˆ‘ä»¬éœ€è¦æ„å»º 0/1 æ ‡ç­¾ï¼š1 ä¸º Clean, 0 ä¸º Dirty (æˆ–è€…åè¿‡æ¥)
    # è¿™é‡Œå®šä¹‰ï¼šClean=1, Dirty=0
    true_labels = np.ones(len(raw_data))
    true_labels[dirty_indices] = 0
    
    # è®¡ç®— ROC-AUC
    # æ³¨æ„ï¼šæˆ‘ä»¬çš„ sv è¶Šé«˜è¶Š cleanï¼Œç¬¦åˆ y=1 çš„æ–¹å‘
    roc_auc = roc_auc_score(true_labels, sv)
    print(f"ğŸ“ˆ æ¸…æ´—ç®—æ³• AUC å¾—åˆ†: {roc_auc:.4f} (1.0ä»£è¡¨å®Œç¾åŒºåˆ†)")
    print("-" * 50)
    
    # 5. SFT å¯¹æ¯”å®éªŒ (Baseline vs Clean)
    # æ³¨æ„ï¼šä¸ºäº†å…¬å¹³ï¼ŒBaseline æˆ‘ä»¬é€šå¸¸ä¸åˆ æ•°æ®ï¼Œæˆ–è€…éšæœºåˆ ã€‚
    # è¿™é‡Œå¯¹æ¯”ï¼šDirty Full Set vs Cleaned Set
    
    # 5.1 è®­ç»ƒ Dirty Model
    import gc
    torch.cuda.empty_cache()
    gc.collect()
    loss_dirty, rouge_dirty = run_sft(raw_data, "dirty_model")
    
    # 5.2 è®­ç»ƒ Clean Model
    import gc
    torch.cuda.empty_cache()
    gc.collect()
    loss_clean, rouge_clean = run_sft(cleaned_data, "clean_model")
    
    # 5.3 è®­ç»ƒ Oracle Model (å…¨å¹²å‡€æ•°æ® - ç†è®ºä¸Šé™)
    # ç”¨æˆ·æŒ‡ç¤ºï¼šå·²è®­ç»ƒè¿‡ Oracleï¼Œç›´æ¥ä½¿ç”¨ä¸Šæ¬¡ç»“æœï¼ŒèŠ‚çœæ—¶é—´
    print("â© è·³è¿‡ Oracle Model è®­ç»ƒ (å·²å­˜åœ¨)...")
    loss_oracle = 1.5928  # ä¸Šæ¬¡è¿è¡Œè®°å½•
    rouge_oracle = 0.1701 # ä¸Šæ¬¡è¿è¡Œè®°å½•
    
    print("=" * 50)
    print("ğŸ“Š æœ€ç»ˆå®éªŒç»“æœ")
    print(f"{'Model':<15} | {'Loss':<10} | {'ROUGE-L':<10}")
    print("-" * 45)
    print(f"{'Dirty (Base)':<15} | {loss_dirty:.4f}     | {rouge_dirty:.4f}")
    print(f"{'Clean (Yours)':<15} | {loss_clean:.4f}     | {rouge_clean:.4f}")
    print(f"{'Oracle (Top)':<15} | {loss_oracle:.4f}     | {rouge_oracle:.4f}")
    print("-" * 45)
    
    if rouge_clean > rouge_dirty:
        print("âœ… éªŒè¯æˆåŠŸï¼šæ¸…æ´—åæ¨¡å‹çš„ ROUGE åˆ†æ•°æ›´é«˜ï¼Œç”Ÿæˆè´¨é‡æ›´å¥½ï¼")

if __name__ == "__main__":
    main()

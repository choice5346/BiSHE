import os
import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

# =================é…ç½®=================
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__))) # d:\BiSHE
DIRTY_PATH = os.path.join(ROOT_DIR, "SFT", "results", "dirty_model")
CLEAN_PATH = os.path.join(ROOT_DIR, "SFT", "results", "clean_model")
ORACLE_PATH = os.path.join(ROOT_DIR, "SFT", "results", "oracle_model")
# ======================================

def load_model(path, name):
    print(f"â³ æ­£åœ¨åŠ è½½ {name} ... ({path})")
    try:
        # å¼ºåˆ¶ä½¿ç”¨ cpu æˆ–è€… cudaï¼Œè¿™é‡Œæˆ‘ä»¬ä¸ºäº†è§„é¿å¶å‘çš„ TensorCompare é”™è¯¯ï¼Œå…ˆå°è¯• safe load
        # ä½†é€šå¸¸è¿™æ˜¯å› ä¸º embedding æº¢å‡ºæˆ–è€… token id é—®é¢˜ã€‚
        # æˆ‘ä»¬è¿™é‡Œæš‚æ—¶ä¿æŒ cudaï¼Œä½†åŠ ä¸€ä¸ªè®¾ç½®ã€‚
        tokenizer = AutoTokenizer.from_pretrained(path)
        # Qwen çš„è¯è¡¨å¾ˆå¤§ï¼Œæœ‰æ—¶éœ€è¦ resize
        model = AutoModelForCausalLM.from_pretrained(path, device_map="auto", torch_dtype=torch.float16)
        
        # âš ï¸ å…³é”®ä¿®å¤ï¼šQwen1.5 æœ‰æ—¶å€™ eos_token_id å¯èƒ½ä¼šå‡ºé—®é¢˜ï¼Œæ˜¾å¼è®¾ç½® pad
        if tokenizer.pad_token is None:
            tokenizer.pad_token = tokenizer.eos_token
            model.config.pad_token_id = tokenizer.eos_token_id
            
        return tokenizer, model
    except Exception as e:
        print(f"âŒ åŠ è½½ {name} å¤±è´¥: {e}")
        return None, None

def generate_response(model, tokenizer, instruction):
    # æ„é€ ä¸è®­ç»ƒæ—¶ä¸€è‡´çš„ Prompt
    # è®­ç»ƒæ ¼å¼: User: {instruction}\n{input}\nAssistant: {output}
    prompt = f"User: {instruction}\n\nAssistant: "
    
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    
    # æ‰‹åŠ¨å¤„ç† attention_mask (å®‰å…¨èµ·è§)
    # inputs åŒ…å« input_ids å’Œ attention_mask
    
    with torch.no_grad():
        outputs = model.generate(
            **inputs, 
            max_new_tokens=100, 
            do_sample=True,      # å…è®¸é‡‡æ ·
            temperature=0.7,     # æ¸©åº¦
            top_p=0.9,
            pad_token_id=tokenizer.eos_token_id,
            repetition_penalty=1.1 # é¿å…å¤è¯»æœº
        )
    
    response = tokenizer.decode(outputs[0], skip_special_tokens=True)
    # æå– Assistant ä¹‹åçš„éƒ¨åˆ†
    if "Assistant: " in response:
        response = response.split("Assistant: ")[1].strip()
    return response

def main():
    print("="*50)
    print("ğŸ¤– SFT æ¨¡å‹å¯¹æ¯”å¯¹è¯ç³»ç»Ÿ (Dirty vs Clean)")
    print("="*50)

    # 1. æ£€æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(DIRTY_PATH) or not os.path.exists(CLEAN_PATH):
        print("âš ï¸ è­¦å‘Šï¼šæœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼")
        print(f"è¯·æ£€æŸ¥è·¯å¾„:\n  {DIRTY_PATH}\n  {CLEAN_PATH}")
        print("ğŸ’¡ æç¤ºï¼šæ‚¨ä¹‹å‰çš„ sft_demo.py å¯èƒ½æ²¡æœ‰ä¿å­˜æ¨¡å‹ï¼Œè¯·é‡æ–°è¿è¡Œä¸€æ¬¡ sft_demo.py")
        return

    # 2. åŠ è½½æ¨¡å‹
    # è€ƒè™‘åˆ°æ˜¾å­˜ï¼Œæˆ‘ä»¬å‡è®¾ 6GB èƒ½åŒæ—¶æ”¾ä¸‹ä¸¤ä¸ª 0.5B æ¨¡å‹ (çº¦ 2-3GB)
    # å¦‚æœçˆ†æ˜¾å­˜ï¼Œå¯ä»¥æ”¹æˆåŠ è½½ä¸€ä¸ª -> å¯¹è¯ -> å¸è½½ -> åŠ è½½å¦ä¸€ä¸ªï¼Œä½†é‚£æ ·å¤ªæ…¢
    tk_dirty, model_dirty = load_model(DIRTY_PATH, "Dirty Model (è„æ•°æ®è®­ç»ƒ)")
    if not model_dirty: return
    
    tk_clean, model_clean = load_model(CLEAN_PATH, "Clean Model (æ¸…æ´—åè®­ç»ƒ)")
    if not model_clean: return
    
    tk_oracle, model_oracle = load_model(ORACLE_PATH, "Oracle Model (åŸå§‹çº¯å‡€æ•°æ®)")
    # Oracle å¯é€‰ï¼Œå¦‚æœæ²¡æœ‰å°±ä¸åŠ è½½
    if not model_oracle: 
        print("âš ï¸ æç¤ºï¼šæœªæ‰¾åˆ° Oracle æ¨¡å‹ï¼Œå°†åªå¯¹æ¯” Dirty vs Clean")

    print("\nâœ… æ¨¡å‹åŠ è½½å®Œæˆï¼è¯·è¾“å…¥é—®é¢˜è¿›è¡Œæµ‹è¯• (è¾“å…¥ 'q' é€€å‡º)")
    print("-" * 50)

    while True:
        query = input("\nğŸ—£ï¸  User: ")
        if query.lower() in ['q', 'quit', 'exit']:
            break
            
        if not query.strip():
            continue
            
        print("\n" + "-"*20 + " ç”Ÿæˆä¸­ " + "-"*20)
        
        # ç”Ÿæˆ Dirty
        ans_dirty = generate_response(model_dirty, tk_dirty, query)
        print(f"\nğŸ’© Dirty Model (åŸºçº¿):\n{ans_dirty}")
        
        # ç”Ÿæˆ Clean
        ans_clean = generate_response(model_clean, tk_clean, query)
        print(f"\nâœ¨ Clean Model (ä½ çš„ç®—æ³•):\n{ans_clean}")
        
        # ç”Ÿæˆ Oracle
        if model_oracle:
            ans_oracle = generate_response(model_oracle, tk_oracle, query)
            print(f"\nğŸŒŸ Oracle Model (å¤©èŠ±æ¿):\n{ans_oracle}")
        
        print("\n" + "="*50)

if __name__ == "__main__":
    main()
